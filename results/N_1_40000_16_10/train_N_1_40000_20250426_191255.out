INFO:__main__:Initializing Spark...
INFO:__main__:16 cores for spark
25/04/26 19:12:58 WARN Utils: Your hostname, yPC resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)
25/04/26 19:12:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
:: loading settings :: url = jar:file:/home/goodh/miniconda3/envs/5003/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/goodh/.ivy2/cache
The jars for the packages stored in: /home/goodh/.ivy2/jars
org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-44986d21-2c79-47e7-a196-14ca927e798f;1.0
	confs: [default]
	found org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central
	found org.mongodb#mongodb-driver-sync;4.0.5 in central
	found org.mongodb#bson;4.0.5 in central
	found org.mongodb#mongodb-driver-core;4.0.5 in central
:: resolution report :: resolve 87ms :: artifacts dl 4ms
	:: modules in use:
	org.mongodb#bson;4.0.5 from central in [default]
	org.mongodb#mongodb-driver-core;4.0.5 from central in [default]
	org.mongodb#mongodb-driver-sync;4.0.5 from central in [default]
	org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-44986d21-2c79-47e7-a196-14ca927e798f
	confs: [default]
	0 artifacts copied, 4 already retrieved (0kB/3ms)
25/04/26 19:12:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/04/26 19:12:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
INFO:__main__:No cached Parquet files found. Running full pipeline...
INFO:__main__:Loading data to MongoDB...
INFO:__main__:Loading IMDB dataset...
INFO:__main__:Loading SST-2 dataset...
INFO:__main__:Writing datasets to MongoDB...
25/04/26 19:13:30 WARN TaskSetManager: Stage 0 contains a task of very large size (3984 KiB). The maximum recommended task size is 1000 KiB.
[Stage 0:>                                                        (0 + 16) / 16]                                                                                INFO:__main__:Data loading to MongoDB took 32.07 seconds
INFO:__main__:Distributed preprocessing and saving to Parquet...
INFO:__main__:Reading data from MongoDB...
INFO:__main__:Applying text preprocessing (lowercase, remove punctuation, non-alnum, continuous whitespace, strip)...
INFO:__main__:Tokenizing data...
INFO:__main__:num_samples[40000]
INFO:__main__:num_partitions 16
INFO:__main__:Writing Parquet files: train=processed_data/train_9095d496419c4ec185cadf5df18dcae8, test=processed_data/test_390a5929aa504219a8c4105720e371c5, sst2=processed_data/sst2_55e9682b37a3438283fd86276050a5d0
25/04/26 19:13:32 WARN TaskSetManager: Stage 2 contains a task of very large size (3984 KiB). The maximum recommended task size is 1000 KiB.
[Stage 2:>                                                        (0 + 16) / 32][Stage 2:=>                                                       (1 + 16) / 32][Stage 2:=======>                                                 (4 + 16) / 32][Stage 2:============>                                            (7 + 16) / 32][Stage 2:============================>                           (16 + 16) / 32][Stage 2:===============================>                        (18 + 14) / 32][Stage 2:=================================>                      (19 + 13) / 32][Stage 2:======================================>                 (22 + 10) / 32][Stage 2:===================================================>     (29 + 3) / 32][Stage 7:>                                                        (0 + 16) / 16]                                                                                INFO:__main__:25.2162s for train_df partition
25/04/26 19:13:57 WARN TaskSetManager: Stage 8 contains a task of very large size (3984 KiB). The maximum recommended task size is 1000 KiB.
[Stage 8:>                                                        (0 + 16) / 32][Stage 8:===>                                                     (2 + 16) / 32][Stage 8:=====>                                                   (3 + 16) / 32][Stage 8:==========>                                              (6 + 16) / 32][Stage 8:===================>                                    (11 + 16) / 32][Stage 8:=================================>                      (19 + 13) / 32][Stage 8:====================================>                   (21 + 11) / 32][Stage 8:======================================>                 (22 + 10) / 32][Stage 8:============================================>            (25 + 7) / 32][Stage 8:================================================>        (27 + 5) / 32][Stage 8:===================================================>     (29 + 3) / 32][Stage 8:=====================================================>   (30 + 2) / 32][Stage 8:=======================================================> (31 + 1) / 32]                                                                                INFO:__main__:19.8001s for test_df partition
25/04/26 19:14:17 WARN TaskSetManager: Stage 14 contains a task of very large size (3984 KiB). The maximum recommended task size is 1000 KiB.
[Stage 14:==================>                                    (11 + 16) / 32][Stage 14:======================>                                (13 + 16) / 32][Stage 14:========================>                              (14 + 16) / 32][Stage 14:========================================>               (23 + 9) / 32][Stage 14:==========================================>             (24 + 8) / 32][Stage 14:===========================================>            (25 + 7) / 32][Stage 14:=============================================>          (26 + 6) / 32][Stage 14:===============================================>        (27 + 5) / 32][Stage 14:=================================================>      (28 + 4) / 32][Stage 14:====================================================>   (30 + 2) / 32][Stage 14:======================================================> (31 + 1) / 32]                                                                                INFO:__main__:10.3147s for sst2_df partition
INFO:__main__:Distributed preprocessing took 55.53 seconds
INFO:__main__:2025/04/26-19:14:27	NUM_CPUs[16]		NUM_GPUs[1]		NUM_TRAIN_SAMPLES[40000]		preprocess_time[55.53 sec]

INFO:py4j.clientserver:Closing down clientserver connection
